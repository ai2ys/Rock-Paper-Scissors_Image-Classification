{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 02:19:05.082271: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-19 02:19:05.082312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-19 02:19:05.082334: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-19 02:19:05.089577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from numba import cuda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "workspace_dir = os.environ.get('WORKSPACE_DIR', '/workspace')\n",
    "\n",
    "path_lib_dir = os.path.join(workspace_dir, 'lib')\n",
    "# check if path has been added\n",
    "if os.path.dirname(os.path.abspath(path_lib_dir)) not in sys.path:\n",
    "    sys.path.append(path_lib_dir)\n",
    "\n",
    "from lib.dataset import Dataset\n",
    "from lib.augment import Processing\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# jupyter notebook make changes in imports to update without restarting kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check TensorFlow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numba.cuda.cudadrv.driver:init\n",
      "INFO:numba.cuda.cudadrv.driver:reset context of device 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Default GPU Device: /device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 02:19:08.675686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 22981 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "2023-12-19 02:19:08.676744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 22981 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()\n",
    "else:\n",
    "    print(\"GPU not available\")\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /root/tensorflow_datasets/rock_paper_scissors/3.0.0\n",
      "INFO:absl:Reusing dataset rock_paper_scissors (/root/tensorflow_datasets/rock_paper_scissors/3.0.0)\n",
      "2023-12-19 02:19:08.737909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22981 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "INFO:absl:Constructing tf.data.Dataset rock_paper_scissors for split ['train'], from /root/tensorflow_datasets/rock_paper_scissors/3.0.0\n",
      "INFO:absl:Load dataset info from /root/tensorflow_datasets/rock_paper_scissors/3.0.0\n",
      "INFO:absl:Reusing dataset rock_paper_scissors (/root/tensorflow_datasets/rock_paper_scissors/3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Constructing tf.data.Dataset rock_paper_scissors for split ['train[:2142]', 'train[2142:]', 'test'], from /root/tensorflow_datasets/rock_paper_scissors/3.0.0\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "# Set the seed for reproducibility\n",
    "# tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "dataset = Dataset(seed=seed, dataset_name='rock_paper_scissors')\n",
    "dataset.load(validation_proportion=0.15)\n",
    "\n",
    "ds_train = dataset.ds_train\n",
    "ds_val = dataset.ds_val\n",
    "\n",
    "# retrieve length of dataset from ds_train\n",
    "len_ds_train = len(ds_train)\n",
    "len_ds_val = len(ds_val)\n",
    "len_ds_test = len(dataset.ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of images per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2142, 378, 372)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ds_train, len_ds_val, len_ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_count 12\n",
      "workers 10\n"
     ]
    }
   ],
   "source": [
    "# get cpu threads \n",
    "cpu_count = os.cpu_count()\n",
    "workers = max(1, cpu_count - 2)\n",
    "print('cpu_count', cpu_count)\n",
    "print('workers', workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(ds, seed, target_size=(224, 224), batch_size=64, augment=True, shuffle=True):\n",
    "    preprocessing = Processing(\n",
    "        random_flip_left_right=True,\n",
    "        random_brightness=0.1,\n",
    "        random_contrast=0.1,\n",
    "        random_rotation=180,\n",
    "        random_saturation=0.1,\n",
    "        random_hue=0.05,\n",
    "        random_crop=0.05,\n",
    "        random_translate=0.05,\n",
    "        random_zoom=0.05,\n",
    "    )\n",
    "    ds_prepared = ds.cache()\n",
    "    # ds_prepared = ds\n",
    "    if shuffle:\n",
    "        ds_prepared = ds_prepared.shuffle(len(ds_prepared), seed=seed)\n",
    "    ds_prepared = preprocessing.preprocess(ds_prepared, target_size, augment)\n",
    "    ds_prepared = ds_prepared.batch(batch_size)\n",
    "    ds_prepared = ds_prepared.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "overview_models = { }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following best practice from\n",
    "https://www.tensorflow.org/guide/keras/transfer_learning\n",
    "\n",
    "Function for creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(model_class, seed, target_size=(160, 160), dropout_rate=0.2, optimizer=tf.keras.optimizers.legacy.Adam()):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    input_shape=target_size + (3,)\n",
    "    seed_init = seed\n",
    "    base_model = model_class(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    # freeze base model\n",
    "    base_model.trainable = False\n",
    "    # set base model to inference mode (not training)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "\n",
    "    # add head comparable to original MobileNetV2\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "     # add additional layers in case of dropout is not None\n",
    "    if dropout_rate is not None:\n",
    "        # Add a fully-connected layer\n",
    "        seed_init += 1\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed_init)\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu', kernel_initializer=initializer)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    seed_init += 1\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=seed_init)\n",
    "    outputs = tf.keras.layers.Dense(3, activation='softmax', kernel_initializer=initializer)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model, \n",
    "        model_name, \n",
    "        overview_models, \n",
    "        ds_train, \n",
    "        ds_val,\n",
    "        seed, \n",
    "        target_size, \n",
    "        workers,\n",
    "        batch_size=64,\n",
    "        epochs=20,\n",
    "        callbacks=None,\n",
    "        ):\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    ds_train_prepared = prepare_dataset(\n",
    "        ds_train, seed, target_size=target_size, batch_size=batch_size, augment=True, shuffle=True)\n",
    "    ds_val_prepared = prepare_dataset(\n",
    "        ds_val, seed, target_size=target_size, batch_size=batch_size, augment=False, shuffle=False)\n",
    "\n",
    "    #ds_train_prepared = ds_train_prepared.repeat()\n",
    "    history = model.fit(\n",
    "        ds_train_prepared,\n",
    "        epochs=epochs,\n",
    "        # batch_size=batch_size,\n",
    "        validation_data=ds_val_prepared,\n",
    "        workers=workers,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    y_true = np.concatenate([y for x, y in ds_val_prepared], axis=0)\n",
    "    y_pred = np.argmax(model.predict(ds_val_prepared), axis=1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    overview_models[model_name] = {}\n",
    "    overview_models[model_name]['model'] = model\n",
    "    overview_models[model_name]['num_params'] = model.count_params()\n",
    "    overview_models[model_name]['history'] = history.history\n",
    "    overview_models[model_name]['cm'] = cm\n",
    "\n",
    "    return overview_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting the history (dict for different models and histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(overview_models, plot_model_size=True, ymin_accuracy=None, ymax_accuracy=None, ymin_loss=None, ymax_loss=None):\n",
    "    nplot = 3 if plot_model_size else 2\n",
    "    plt.figure(figsize=(nplot*6, 5))\n",
    "    colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "\n",
    "    alpha = 0.6\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, nplot, 1)\n",
    "    for i, (model_name, overview) in enumerate(overview_models.items()):\n",
    "        history = overview['history']\n",
    "        color = colors[i % len(colors)]\n",
    "        plt.plot(history['accuracy'], label=f'{model_name} Train', linestyle='solid', color=color, alpha=alpha)\n",
    "        plt.plot(history['val_accuracy'], label=f'{model_name} Validation', linestyle='dashed', color=color, alpha=alpha)\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    if ymin_accuracy is not None:\n",
    "        plt.ylim(ymin_accuracy, 1 if ymax_accuracy is None else ymax_accuracy)\n",
    "        \n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, nplot, 2)\n",
    "    for i, (model_name, overview) in enumerate(overview_models.items()):\n",
    "        history = overview['history']\n",
    "        color = colors[i % len(colors)]\n",
    "        plt.plot(history['loss'], label=f'{model_name} Train', linestyle='solid', color=color)\n",
    "        plt.plot(history['val_loss'], label=f'{model_name} Validation', linestyle='dashed', color=color)\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    if ymax_loss is not None:\n",
    "        plt.ylim(0 if ymin_loss is None else ymin_loss, ymax_loss)\n",
    "    plt.legend()\n",
    "\n",
    "    if plot_model_size:\n",
    "        # Plot model size vs validation accuracy in the last epoch\n",
    "        plt.subplot(1, 3, 3)\n",
    "        min_val = np.inf\n",
    "        max_val = 0\n",
    "        for i, (model_name, overview) in enumerate(overview_models.items()):\n",
    "            history = overview['history']\n",
    "            model_size = overview['num_params']\n",
    "            val_accuracy_last_epoch = history['val_accuracy'][-1]\n",
    "            plt.scatter(model_size, val_accuracy_last_epoch, color=colors[i % len(colors)], label=model_name, alpha=alpha)\n",
    "            min_val = min(min_val, model_size)\n",
    "            max_val = max(max_val, model_size)\n",
    "        plt.title('Model size vs Validation accuracy')\n",
    "        plt.xlim(min_val*0.9, max_val*1.1)\n",
    "        plt.ylabel('Validation accuracy in the last epoch')\n",
    "        plt.xlabel('Model size')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cm(overview_models):\n",
    "    num_models = len(overview_models)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=num_models, figsize=(3*num_models, 3))\n",
    "\n",
    "    for ax, (model_name, model_info) in zip(axes, overview_models.items()):\n",
    "        # Get the confusion matrix\n",
    "        cm = model_info['cm']\n",
    "        cm_normalized = normalize(cm, axis=1, norm='l1')\n",
    "\n",
    "        cax = ax.matshow(cm_normalized, cmap=plt.cm.Blues)\n",
    "        fig.colorbar(cax, ax=ax)\n",
    "        ax.set_title(f'{model_name}')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('True')\n",
    "\n",
    "        for i in range(cm_normalized.shape[0]):\n",
    "            for j in range(cm_normalized.shape[1]):\n",
    "                ax.text(j, i, f\"{cm_normalized[i, j]:.2f}\\n({cm[i, j]})\", ha=\"center\", va=\"center\", color=\"red\")\n",
    "\n",
    "    plt.suptitle('Confusion Matrices, normalized value, absolute values in brackets')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the base model\n",
    "\n",
    "Selecting different base models for applying Transfer-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "func_mobilenetv2 = tf.keras.applications.MobileNetV2\n",
    "func_densenet121 = tf.keras.applications.DenseNet121\n",
    "\n",
    "target_size_mobilenetv2 = (160, 160)\n",
    "target_size_densenet121 = (200, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training models using the smallest supported input image size for each base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:training model MobileNetV2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 02:19:18.114888: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 12s 201ms/step - loss: 0.7702 - accuracy: 0.6662 - val_loss: 0.4243 - val_accuracy: 0.8439\n",
      "Epoch 2/20\n",
      "25/34 [=====================>........] - ETA: 1s - loss: 0.2927 - accuracy: 0.9262"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "dropout_rate = None\n",
    "\n",
    "logging.info(f'training model MobileNetV2')\n",
    "model_mobilenetv2 = create_model(func_mobilenetv2, seed=seed, target_size=target_size_mobilenetv2, dropout_rate=dropout_rate)\n",
    "overview = train_model(\n",
    "    model_mobilenetv2, \n",
    "    'MobileNetV2', \n",
    "    overview_models, \n",
    "    ds_train, \n",
    "    ds_val, \n",
    "    seed, \n",
    "    target_size=target_size_mobilenetv2, \n",
    "    workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "logging.info(f'training model DenseNet121')\n",
    "model_densenet121 = create_model(func_densenet121, seed=seed, target_size=target_size_densenet121, dropout_rate=dropout_rate)\n",
    "overview = train_model(\n",
    "    model_densenet121, \n",
    "    'DenseNet121', \n",
    "    overview_models, \n",
    "    ds_train, \n",
    "    dataset.ds_val, \n",
    "    seed, \n",
    "    target_size=target_size_densenet121, \n",
    "    workers=workers,\n",
    "    batch_size=batch_size,  \n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_history(overview_models, ymin_accuracy=0.9, ymax_loss=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_cm(overview_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetv2 with input size (160,160) has less parameter than DenseNet121 with input size (200,200). Difference in performance (accuracy) is small. Therefore deciding to chose the smaller MobileNetv2 model for further investigations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Starting hyperparameter tuning\n",
    "\n",
    "### Additional layer with different dropout rates\n",
    "\n",
    "Trying out an additional layer with different dropout rates.\n",
    "\n",
    "Furthermore comparing it to the model without addtional layer from previous training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "overview_mobilenetv2 = {}\n",
    "overview_mobilenetv2['MobileNetV2'] = overview_models['MobileNetV2']\n",
    "\n",
    "epochs=20\n",
    "target_size=(160, 160)\n",
    "batch_size=64\n",
    "\n",
    "for dropout_rate in [0.0, 0.2, 0.4, 0.6]:\n",
    "    logging.info(f'training model MobileNetV2 - additional layer with dropout {dropout_rate}')\n",
    "    model_mobilenetv2_dropout = create_model(func_mobilenetv2, seed=seed, target_size=target_size, dropout_rate=dropout_rate)\n",
    "    overview_mobilenetv2 = train_model(\n",
    "        model_mobilenetv2_dropout, \n",
    "        f'MobileNetV2 dropout {dropout_rate}', \n",
    "        overview_mobilenetv2, \n",
    "        ds_train, \n",
    "        ds_val, \n",
    "        seed, \n",
    "        target_size=target_size, \n",
    "        workers=workers,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_history(\n",
    "    overview_mobilenetv2, plot_model_size=True, \n",
    "    ymin_accuracy=0.9, ymax_accuracy=1.0,\n",
    "    ymin_loss=0, ymax_loss=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_cm(overview_mobilenetv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model performance is more smooth for all models on training set as validation set.\n",
    "\n",
    "1. Model without additional layer and and dropout has more smooth training curve than other models. But seems to learn more slowly than the others.\n",
    "\n",
    "1. Selecting a moderate dropout of `0.4` as it has a good performance aftrer the last epoch. Higher dropout rate results in worse performance.\n",
    "\n",
    "Next comparing performance to using learning rate decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dropout_rate=0.4\n",
    "overview_mobilenetv2_lr_schedule = {}\n",
    "overview_mobilenetv2_lr_schedule['MobileNetV2'] = overview_mobilenetv2[f'MobileNetV2 dropout {dropout_rate}']\n",
    "\n",
    "epochs=20\n",
    "target_size=(160, 160)\n",
    "batch_size=64\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-2,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=epochs * 34,  # Total number of batches in 20 epochs\n",
    "    decay_rate=(1e-4 / 1e-2) ** (1 / (20 * 34))  # Calculate decay rate\n",
    ")\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model_mobilenetv2_lr_schedule = create_model(\n",
    "    func_mobilenetv2, seed=seed, target_size=target_size, dropout_rate=dropout_rate, optimizer=optimizer)\n",
    "overview_mobilenetv2_lr_schedule = train_model(\n",
    "    model_mobilenetv2_lr_schedule, \n",
    "    'MobileNetV2 lr schedule', \n",
    "    overview_mobilenetv2_lr_schedule, \n",
    "    ds_train, \n",
    "    ds_val, \n",
    "    seed, \n",
    "    target_size=target_size, \n",
    "    workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_history(\n",
    "    overview_mobilenetv2_lr_schedule, plot_model_size=False, \n",
    "    ymin_accuracy=0.9, ymax_accuracy=1.001,\n",
    "    ymin_loss=0, ymax_loss=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "plot_cm(overview_mobilenetv2_lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model trained using the learning rate schedule has a more \"jumpy\" curve for the valdidation split. \n",
    "\n",
    "Therefore deciding to not apply the learning rate schedule for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion/Summary\n",
    "\n",
    "The following has been tried out. Unfortunately, it was not possible to do the augmentation of the dataset in a reproducible way. Therefore running the notebook again could result in slightly different results.\n",
    "\n",
    "1. **Different base models:**<br>\n",
    "Training models based on different model architectures. MobileNetv2 has less parameters and performed better.\n",
    "    - MobileNetv2 with input size (160,160)\n",
    "    - DenseNet121 with input size (200,200)\n",
    "    - Remark: DenseNet base model was not available for smaller images sizes\n",
    "    - MobileNetv2 did perform better within `20` epochs and is smaller\n",
    "\n",
    "1. **Additional Layer without and with different dropout rates:**<br>\n",
    "Training MobileNetv2 models with and additional dense layer and different dropout rates and comparing it to the MobileNetv2 model for the previous step.\n",
    "    - dropout rates `0.0`, `0.2`, `0.4`., and `0.6` have been tried out\n",
    "    - Curves for validation accuracy are more 'jumpy' than for the 'original' model without the additional layer, but perform better within `20` epochs.\n",
    "   - Chosing moderate dropout rate of `0.4`\n",
    "     \n",
    "1. **Differnt learning rates/schedules:**<br>\n",
    "Training MobileNetv2 models (additional dense layer and dropout `0.4`) with and without learning rate decay. The model with learning rate decay has again a more 'jumpy' validation accuracy.\n",
    "   - Selcecting the model without learning rate schedule\n",
    "\n",
    "Final Model \n",
    "\n",
    "- MobileNetv2 with input size (160,160)\n",
    "- with additional dense layer and dropout `0.4`\n",
    "- no learning rate decay\n",
    "- Stopping training after 10 epochs\n",
    "\n",
    "Check performance on test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the final model using `train` and `validation` splits, but saving the best model based on `val_loss`. Afterwards choosing the best model for evaluating it finally with the `test` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "overview_final = {}\n",
    "\n",
    "# clear all from memory of previous run\n",
    "# prevent error from datetime import datetime\n",
    "overview_final = {}\n",
    "\n",
    "# clear all from memory of previous run\n",
    "# prevent error from datetime import datetime\n",
    "overview_final = {}\n",
    "\n",
    "epochs=20\n",
    "target_size = (160, 160)\n",
    "batch_size = 64\n",
    "dropout_rate = 0.4\n",
    "\n",
    "path_model_dir = 'final_model'\n",
    "shutil.rmtree(path_model_dir, ignore_errors=True)\n",
    "# Check if the directory exists, and create it if not\n",
    "# os.makedirs(path_model_dir, exist_ok=True)\n",
    "\n",
    "# # Optional: Remove existing files in the directory\n",
    "# existing_files = os.listdir(path_model_dir)\n",
    "# for file_name in existing_files:\n",
    "#     file_path = os.path.join(path_model_dir, file_name)\n",
    "#     os.remove(file_path)\n",
    "#     print(f\"Removed existing file: {file_path}\")\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(path_model_dir, f'model_{datetime.now():%Y%m%d_%H%M%S}'+'-{epoch:02d}-{val_accuracy:.4f}.h5'), \n",
    "    monitor='val_accuracy',\n",
    "    save_weights_only=True,\n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='auto')\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "final_model = create_model(func_mobilenetv2, seed=seed, target_size=target_size_mobilenetv2, dropout_rate=dropout_rate)\n",
    "overview_final = train_model(\n",
    "    final_model, \n",
    "    'MobileNetV2 final', \n",
    "    overview_final, \n",
    "    ds_train, \n",
    "    ds_val, \n",
    "    seed, \n",
    "    target_size=target_size, \n",
    "    workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# can not run twice without restarting kernel\n",
    "final_model.save(os.path.join(path_model_dir, f'model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model with best `val_loss` and evaluating it on the `validation` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# plot overview_final\n",
    "plot_history(\n",
    "    overview_final, plot_model_size=False, \n",
    "    ymin_accuracy=0.9, ymax_accuracy=1.001,\n",
    "    ymin_loss=0, ymax_loss=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "os.path.join(path_model_dir, sorted(os.listdir(path_model_dir))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# get latest file in directory \n",
    "path_model_weights = os.path.join(path_model_dir, sorted(os.listdir(path_model_dir))[-1])\n",
    "print(path_model_weights)\n",
    "print(os.path.exists(path_model_weights))\n",
    "final_model = tf.keras.models.load_model(os.path.join(path_model_dir,'model.h5'))\n",
    "final_model.load_weights(path_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds_test_prepared = prepare_dataset(dataset.ds_test, seed, target_size=target_size, batch_size=batch_size, augment=False, shuffle=False)\n",
    "y_true = np.concatenate([y for x, y in ds_test_prepared], axis=0)\n",
    "y_pred = np.argmax(final_model.predict(ds_test_prepared), axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "cm_normalized = normalize(cm, axis=1, norm='l1')\n",
    "\n",
    "cax = ax.matshow(cm_normalized, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax, ax=ax)\n",
    "ax.set_title('MobileNetV2 final - performance on test dataset')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "\n",
    "for i in range(cm_normalized.shape[0]):\n",
    "    for j in range(cm_normalized.shape[1]):\n",
    "        ax.text(j, i, f\"{cm_normalized[i, j]:.2f}\\n({cm[i, j]})\", ha=\"center\", va=\"center\", color=\"red\")\n",
    "\n",
    "# print labels\n",
    "labels = dataset.ds_info.features['label'].names\n",
    "num_labels = len(labels)\n",
    "ax.set_xticks(np.arange(num_labels))\n",
    "ax.set_yticks(np.arange(num_labels))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "\n",
    "loss, accuracy = final_model.evaluate(ds_test_prepared)\n",
    "print(\"Evaluation on test data\")\n",
    "print(f\"Loss: {loss:.3f}\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting training logic to separate script [`train.py`](train.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
